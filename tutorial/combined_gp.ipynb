{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for CombinedTree and CombinedForest\n",
    "## 1. Introduction\n",
    "### 1.1 What is a CombinedTree?\n",
    "A **CombinedTree** is an individual tree-based model that follows a _manually specified_ computation rule (a formula) but is split into multiple parts (sub-trees). Each part is an independent tree evolved by the genetic algorithm. For example, if you have:\n",
    "\n",
    "```python\n",
    "formula = lambda A, B, C: A + B * C\n",
    "```\n",
    "\n",
    "- `A`, `B`, and `C` are considered separate sub-trees, each evolved independently.\n",
    "- The final output of the CombinedTree is computed by substituting the outputs of sub-trees `A`, `B`, `C` into the formula (`A + B * C`).\n",
    "\n",
    "### 1.2 What is a CombinedForest?\n",
    "A **CombinedForest** is simply a _population_ of CombinedTrees. Since EvoGP is a population-based genetic programming framework, we often manipulate and evaluate populations (forests) as the central objects rather than individual solutions (trees). \n",
    "\n",
    "Thus, practically, we usually:\n",
    "1. Define a **CombinedForest** which internally maintains multiple sub-forests (one for each parameter).\n",
    "2. Evolve it via the usual genetic operators (selection, crossover, mutation) in EvoGP.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How to Create a CombinedForest\n",
    "\n",
    "When creating a **CombinedForest**, there are three important elements to provide:\n",
    "\n",
    "1. **Formula** (the computation rule).\n",
    "2. **Descriptors** (the blueprint that controls how each sub-tree is generated and mutated).\n",
    "3. **Population size** (`pop_size`).\n",
    "4. **share_input** (Whether all patterns in the formula share the same input, currently it **MUST be True**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Defining a Formula\n",
    "A formula must be a Python callable (e.g., `lambda`) that:\n",
    "- Has _at least one_ parameter.  \n",
    "- Uses only supported operations (e.g., `+`, `-`, `*`, `/`, or certain PyTorch math functions like `torch.pow`, `torch.tan`, etc.) to combine the parameters.  \n",
    "\n",
    "For example:\n",
    "```python\n",
    "formula = lambda A, B, C: A + B * C\n",
    "```\n",
    "or \n",
    "```python\n",
    "formula = lambda A, B: torch.pow(A, B)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Descriptors\n",
    "**Descriptors** in EvoGP define how trees (individuals) are generated and mutated. Each parameter in your formula corresponds to one descriptor.\n",
    "\n",
    "- **Single Descriptor**: You can pass one `GenerateDescriptor` object if you want _all parameters_ (`A`, `B`, `C`, ...) to be generated with the same rules.\n",
    "- **List of Descriptors**: If you need different rules for each parameter, supply a list of descriptors, one per formula parameter.\n",
    "\n",
    "Check out `evogp_intro.ipynb` or the main EvoGP tutorials for details on `GenerateDescriptor`. Here is a reminder of what it might look like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evogp.tree import CombinedForest, GenerateDescriptor\n",
    "descriptor = GenerateDescriptor(\n",
    "    max_tree_len=16,\n",
    "    input_len=3,\n",
    "    output_len=1,\n",
    "    using_funcs=[\"+\", \"-\", \"*\", \"/\", \"neg\"],  # Allowed function set\n",
    "    max_layer_cnt=4,\n",
    "    const_samples=[0, 0.5, 1]  # constant choices\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evolving a CombinedForest with an Algorithm\n",
    "\n",
    "In EvoGP, after you create a **CombinedForest**, you typically feed it into a genetic algorithm pipeline. This pipeline handles:\n",
    "1. **Selection**: how individuals are chosen for breeding (or carried forward as elites). \n",
    "2. **Crossover**: how two individuals exchange parts of their trees.\n",
    "3. **Mutation**: how individuals are altered (sub-trees replaced, etc.).\n",
    "\n",
    "You can just use the followings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evogp.algorithm import (\n",
    "    DefaultSelection,\n",
    "    CombinedDefaultMutation,\n",
    "    CombinedDefaultCrossover,\n",
    ")\n",
    "crossover=CombinedDefaultCrossover()\n",
    "mutation=CombinedDefaultMutation(\n",
    "    mutation_rate=0.2, descriptors=descriptor\n",
    ")\n",
    "selection=DefaultSelection(survival_rate=0.3, elite_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Converting a CombinedTree (or CombinedForest) to Sympy Expressions\n",
    "\n",
    "Once you have evolved a best solution (or a set of solutions), you can:\n",
    "- Access each parameter sub-tree directly (e.g., `best.A`, `best.B`, `best.C`).\n",
    "- Convert these sub-trees into **sympy expressions** by calling `.to_sympy_expr()`.\n",
    "- Convert the **entire** CombinedTree into a Sympy expression using `combined_tree.to_sympy_expr(SYMPY_FORMULA)`, which will apply your top-level formula to each sub-tree's Sympy form.\n",
    "\n",
    "This is helpful for interpretability (e.g., to see an analytic formula of your best solution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nessary packages\n",
    "import torch\n",
    "from evogp.tree import CombinedForest, GenerateDescriptor\n",
    "from evogp.algorithm import (\n",
    "    GeneticProgramming,\n",
    "    DefaultSelection,\n",
    "    CombinedDefaultMutation,\n",
    "    CombinedDefaultCrossover,\n",
    ")\n",
    "from evogp.problem import SymbolicRegression\n",
    "from evogp.pipeline import StandardPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sample XOR data (running on CUDA for speed, but CPU is fine)\n",
    "XOR_INPUTS = torch.tensor(\n",
    "    [\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 1],\n",
    "        [0, 1, 0],\n",
    "        [0, 1, 1],\n",
    "        [1, 0, 0],\n",
    "        [1, 0, 1],\n",
    "        [1, 1, 0],\n",
    "        [1, 1, 1],\n",
    "    ],\n",
    "    dtype=torch.float,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "XOR_OUTPUTS = torch.tensor(\n",
    "    [[0], [1], [1], [0], [1], [0], [0], [1]],\n",
    "    dtype=torch.float,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "# Define a symbolic regression problem\n",
    "problem = SymbolicRegression(\n",
    "    datapoints=XOR_INPUTS, \n",
    "    labels=XOR_OUTPUTS, \n",
    "    execute_mode=\"torch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a descriptor for generating sub-trees\n",
    "descriptor = GenerateDescriptor(\n",
    "    max_tree_len=16,\n",
    "    input_len=problem.problem_dim,   # 3 inputs for the XOR\n",
    "    output_len=problem.solution_dim, # 1 output\n",
    "    using_funcs=[\"+\", \"-\", \"*\", \"/\"],\n",
    "    max_layer_cnt=4,\n",
    "    const_samples=[0, 0.5, 1]\n",
    ")\n",
    "\n",
    "# Create the initial CombinedForest with a formula. \n",
    "# In this example, we use: formula=lambda A, B, C: A + B * C\n",
    "initial_population = CombinedForest.random_generate(\n",
    "    pop_size=5000,\n",
    "    formula=lambda A, B, C: A + B * C,\n",
    "    descriptors=descriptor,\n",
    "    share_input=True,  # same inputs for both sub-forests\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our GeneticProgramming algorithm with default operators\n",
    "algorithm = GeneticProgramming(\n",
    "    initial_forest=initial_population,\n",
    "    crossover=CombinedDefaultCrossover(),\n",
    "    mutation=CombinedDefaultMutation(\n",
    "        mutation_rate=0.2, \n",
    "        descriptors=descriptor.update(max_layer_cnt=3)\n",
    "    ),\n",
    "    selection=DefaultSelection(survival_rate=0.3, elite_rate=0.01),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 0, Cost time: 155.16ms\n",
      " \tfitness: valid cnt: 781, max: -0.2500, min: -185.5625, mean: -3.1468, std: 9.3311\n",
      "\n",
      "Generation: 1, Cost time: 6.00ms\n",
      " \tfitness: valid cnt: 2272, max: -0.2500, min: -475.5625, mean: -3.0654, std: 12.6313\n",
      "\n",
      "Generation: 2, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4384, max: -0.2188, min: -47.5000, mean: -1.2731, std: 1.7615\n",
      "\n",
      "Generation: 3, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4486, max: -0.1875, min: -64.5000, mean: -0.8127, std: 1.5118\n",
      "\n",
      "Generation: 4, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4519, max: -0.1250, min: -19.3750, mean: -0.6665, std: 0.8676\n",
      "\n",
      "Generation: 5, Cost time: 4.38ms\n",
      " \tfitness: valid cnt: 4543, max: -0.1250, min: -20.6875, mean: -0.5460, std: 0.7388\n",
      "\n",
      "Generation: 6, Cost time: 6.00ms\n",
      " \tfitness: valid cnt: 4545, max: -0.1250, min: -17.3750, mean: -0.4322, std: 0.5855\n",
      "\n",
      "Generation: 7, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4586, max: -0.1250, min: -100.2500, mean: -0.4729, std: 1.8531\n",
      "\n",
      "Generation: 8, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4582, max: -0.1250, min: -17.7500, mean: -0.4060, std: 0.6221\n",
      "\n",
      "Generation: 9, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4588, max: -0.1250, min: -22.5312, mean: -0.3827, std: 0.6194\n",
      "\n",
      "Generation: 10, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4607, max: -0.1250, min: -16.5000, mean: -0.3721, std: 0.5548\n",
      "\n",
      "Generation: 11, Cost time: 5.35ms\n",
      " \tfitness: valid cnt: 4641, max: -0.1250, min: -9.5000, mean: -0.3559, std: 0.4198\n",
      "\n",
      "Generation: 12, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4617, max: -0.1250, min: -12.1250, mean: -0.3637, std: 0.4877\n",
      "\n",
      "Generation: 13, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4622, max: -0.1250, min: -12.7500, mean: -0.3338, std: 0.3906\n",
      "\n",
      "Generation: 14, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4566, max: -0.1250, min: -14.5000, mean: -0.3588, std: 0.5588\n",
      "\n",
      "Generation: 15, Cost time: 4.97ms\n",
      " \tfitness: valid cnt: 4612, max: -0.1250, min: -8.5000, mean: -0.3475, std: 0.4321\n",
      "\n",
      "Generation: 16, Cost time: 5.03ms\n",
      " \tfitness: valid cnt: 4615, max: -0.1250, min: -9.5000, mean: -0.3435, std: 0.4172\n",
      "\n",
      "Generation: 17, Cost time: 5.48ms\n",
      " \tfitness: valid cnt: 4625, max: -0.1250, min: -16.2500, mean: -0.3429, std: 0.4695\n",
      "\n",
      "Generation: 18, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4576, max: -0.1250, min: -8.2500, mean: -0.3447, std: 0.4386\n",
      "\n",
      "Generation: 19, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4647, max: -0.1250, min: -8.2500, mean: -0.3348, std: 0.3556\n",
      "\n",
      "Generation: 20, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4591, max: -0.1250, min: -34.5000, mean: -0.3482, std: 0.6627\n",
      "\n",
      "Generation: 21, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4603, max: -0.1250, min: -6.5000, mean: -0.3402, std: 0.3754\n",
      "\n",
      "Generation: 22, Cost time: 6.00ms\n",
      " \tfitness: valid cnt: 4602, max: -0.1113, min: -13.2500, mean: -0.3297, std: 0.3866\n",
      "\n",
      "Generation: 23, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4606, max: -0.1113, min: -18.2500, mean: -0.3512, std: 0.5549\n",
      "\n",
      "Generation: 24, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4612, max: -0.1113, min: -9.7500, mean: -0.3382, std: 0.4392\n",
      "\n",
      "Generation: 25, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4649, max: -0.0625, min: -20.2500, mean: -0.3453, std: 0.6004\n",
      "\n",
      "Generation: 26, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4604, max: -0.0625, min: -9.5000, mean: -0.3364, std: 0.3900\n",
      "\n",
      "Generation: 27, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4596, max: -0.0625, min: -19.3750, mean: -0.3277, std: 0.4892\n",
      "\n",
      "Generation: 28, Cost time: 5.99ms\n",
      " \tfitness: valid cnt: 4613, max: -0.0625, min: -26.2500, mean: -0.3478, std: 0.6583\n",
      "\n",
      "Generation: 29, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4660, max: -0.0000, min: -27.2500, mean: -0.3502, std: 0.6571\n",
      "\n",
      "Generation: 30, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4621, max: -0.0000, min: -6.7500, mean: -0.3260, std: 0.3438\n",
      "\n",
      "Generation: 31, Cost time: 6.00ms\n",
      " \tfitness: valid cnt: 4637, max: -0.0000, min: -13.0000, mean: -0.3309, std: 0.4540\n",
      "\n",
      "Generation: 32, Cost time: 5.40ms\n",
      " \tfitness: valid cnt: 4575, max: -0.0000, min: -9.2500, mean: -0.3307, std: 0.3942\n",
      "\n",
      "Generation: 33, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4535, max: -0.0000, min: -18.2500, mean: -0.3406, std: 0.5301\n",
      "\n",
      "Generation: 34, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4538, max: -0.0000, min: -18.0000, mean: -0.3436, std: 0.4827\n",
      "\n",
      "Generation: 35, Cost time: 5.65ms\n",
      " \tfitness: valid cnt: 4549, max: -0.0000, min: -22.7500, mean: -0.3570, std: 0.6158\n",
      "\n",
      "Generation: 36, Cost time: 4.99ms\n",
      " \tfitness: valid cnt: 4558, max: -0.0000, min: -32.5000, mean: -0.3568, std: 0.7087\n",
      "\n",
      "Generation: 37, Cost time: 4.97ms\n",
      " \tfitness: valid cnt: 4543, max: -0.0000, min: -9.5000, mean: -0.3506, std: 0.4779\n",
      "\n",
      "Generation: 38, Cost time: 5.03ms\n",
      " \tfitness: valid cnt: 4544, max: -0.0000, min: -82.2500, mean: -0.3844, std: 1.3451\n",
      "\n",
      "Generation: 39, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4524, max: -0.0000, min: -35.2500, mean: -0.3405, std: 0.6568\n",
      "\n",
      "Generation: 40, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4541, max: -0.0000, min: -10.0000, mean: -0.3391, std: 0.4417\n",
      "\n",
      "Generation: 41, Cost time: 5.97ms\n",
      " \tfitness: valid cnt: 4493, max: -0.0000, min: -10.7500, mean: -0.3392, std: 0.4411\n",
      "\n",
      "Generation: 42, Cost time: 5.06ms\n",
      " \tfitness: valid cnt: 4438, max: -0.0000, min: -9.7500, mean: -0.3349, std: 0.4388\n",
      "\n",
      "Generation: 43, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4504, max: -0.0000, min: -16.7500, mean: -0.3456, std: 0.5203\n",
      "\n",
      "Generation: 44, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4530, max: -0.0000, min: -9.5703, mean: -0.3445, std: 0.4856\n",
      "\n",
      "Generation: 45, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4459, max: -0.0000, min: -8.8008, mean: -0.3480, std: 0.4510\n",
      "\n",
      "Generation: 46, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4499, max: -0.0000, min: -12.5625, mean: -0.3497, std: 0.5523\n",
      "\n",
      "Generation: 47, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4446, max: -0.0000, min: -16.2500, mean: -0.3683, std: 0.6245\n",
      "\n",
      "Generation: 48, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4438, max: -0.0000, min: -20.2500, mean: -0.3466, std: 0.5791\n",
      "\n",
      "Generation: 49, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4451, max: -0.0000, min: -12.5000, mean: -0.3446, std: 0.5226\n",
      "\n",
      "Generation: 50, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4427, max: -0.0000, min: -29.0000, mean: -0.3713, std: 0.8431\n",
      "\n",
      "Generation: 51, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4470, max: -0.0000, min: -27.0000, mean: -0.3668, std: 0.7391\n",
      "\n",
      "Generation: 52, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4485, max: -0.0000, min: -12.7500, mean: -0.3491, std: 0.5328\n",
      "\n",
      "Generation: 53, Cost time: 5.43ms\n",
      " \tfitness: valid cnt: 4483, max: -0.0000, min: -24.1250, mean: -0.3656, std: 0.7159\n",
      "\n",
      "Generation: 54, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4456, max: -0.0000, min: -32.7500, mean: -0.3635, std: 0.7801\n",
      "\n",
      "Generation: 55, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4492, max: -0.0000, min: -17.2500, mean: -0.3654, std: 0.5974\n",
      "\n",
      "Generation: 56, Cost time: 6.00ms\n",
      " \tfitness: valid cnt: 4447, max: -0.0000, min: -23.3750, mean: -0.3590, std: 0.7183\n",
      "\n",
      "Generation: 57, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4428, max: -0.0000, min: -21.7500, mean: -0.3646, std: 0.7275\n",
      "\n",
      "Generation: 58, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4446, max: -0.0000, min: -115.8750, mean: -0.3735, std: 1.8242\n",
      "\n",
      "Generation: 59, Cost time: 4.97ms\n",
      " \tfitness: valid cnt: 4505, max: -0.0000, min: -162.2500, mean: -0.4032, std: 2.4947\n",
      "\n",
      "Generation: 60, Cost time: 6.00ms\n",
      " \tfitness: valid cnt: 4441, max: -0.0000, min: -26.2500, mean: -0.3753, std: 0.8628\n",
      "\n",
      "Generation: 61, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4446, max: -0.0000, min: -24.2500, mean: -0.3767, std: 0.8430\n",
      "\n",
      "Generation: 62, Cost time: 6.00ms\n",
      " \tfitness: valid cnt: 4522, max: -0.0000, min: -40.7500, mean: -0.3781, std: 0.8857\n",
      "\n",
      "Generation: 63, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4472, max: -0.0000, min: -18.2500, mean: -0.3862, std: 0.7690\n",
      "\n",
      "Generation: 64, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4494, max: -0.0000, min: -68.2500, mean: -0.4300, std: 1.4155\n",
      "\n",
      "Generation: 65, Cost time: 6.00ms\n",
      " \tfitness: valid cnt: 4462, max: -0.0000, min: -160.2500, mean: -0.4803, std: 3.2651\n",
      "\n",
      "Generation: 66, Cost time: 5.01ms\n",
      " \tfitness: valid cnt: 4451, max: -0.0000, min: -45.2500, mean: -0.3893, std: 0.9781\n",
      "\n",
      "Generation: 67, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4479, max: -0.0000, min: -32.2500, mean: -0.4087, std: 1.0958\n",
      "\n",
      "Generation: 68, Cost time: 6.00ms\n",
      " \tfitness: valid cnt: 4486, max: -0.0000, min: -29.5000, mean: -0.4071, std: 1.0571\n",
      "\n",
      "Generation: 69, Cost time: 5.83ms\n",
      " \tfitness: valid cnt: 4488, max: -0.0000, min: -64.2500, mean: -0.4147, std: 1.4495\n",
      "\n",
      "Generation: 70, Cost time: 5.16ms\n",
      " \tfitness: valid cnt: 4498, max: -0.0000, min: -26.2500, mean: -0.4394, std: 1.0733\n",
      "\n",
      "Generation: 71, Cost time: 4.65ms\n",
      " \tfitness: valid cnt: 4472, max: -0.0000, min: -32.2500, mean: -0.4340, std: 1.1456\n",
      "\n",
      "Generation: 72, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4411, max: -0.0000, min: -64.2500, mean: -0.4568, std: 1.5509\n",
      "\n",
      "Generation: 73, Cost time: 6.00ms\n",
      " \tfitness: valid cnt: 4442, max: -0.0000, min: -37.0000, mean: -0.4282, std: 1.0644\n",
      "\n",
      "Generation: 74, Cost time: 4.78ms\n",
      " \tfitness: valid cnt: 4432, max: -0.0000, min: -26.2500, mean: -0.4374, std: 1.0173\n",
      "\n",
      "Generation: 75, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4476, max: -0.0000, min: -22.7500, mean: -0.4288, std: 0.9479\n",
      "\n",
      "Generation: 76, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4437, max: -0.0000, min: -165.2500, mean: -0.4670, std: 2.7053\n",
      "\n",
      "Generation: 77, Cost time: 6.03ms\n",
      " \tfitness: valid cnt: 4501, max: -0.0000, min: -64.2500, mean: -0.5086, std: 1.7182\n",
      "\n",
      "Generation: 78, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4472, max: -0.0000, min: -24.7500, mean: -0.5002, std: 1.2859\n",
      "\n",
      "Generation: 79, Cost time: 4.97ms\n",
      " \tfitness: valid cnt: 4464, max: -0.0000, min: -25.2500, mean: -0.4743, std: 1.1242\n",
      "\n",
      "Generation: 80, Cost time: 5.03ms\n",
      " \tfitness: valid cnt: 4503, max: -0.0000, min: -54.2500, mean: -0.4665, std: 1.4079\n",
      "\n",
      "Generation: 81, Cost time: 6.00ms\n",
      " \tfitness: valid cnt: 4479, max: -0.0000, min: -96.4375, mean: -0.5568, std: 2.2074\n",
      "\n",
      "Generation: 82, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4500, max: -0.0000, min: -32.2500, mean: -0.4927, std: 1.2915\n",
      "\n",
      "Generation: 83, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4466, max: -0.0000, min: -36.2500, mean: -0.4902, std: 1.4074\n",
      "\n",
      "Generation: 84, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4530, max: -0.0000, min: -50.2500, mean: -0.4927, std: 1.5545\n",
      "\n",
      "Generation: 85, Cost time: 6.00ms\n",
      " \tfitness: valid cnt: 4524, max: -0.0000, min: -151.5000, mean: -0.5684, std: 2.7993\n",
      "\n",
      "Generation: 86, Cost time: 5.01ms\n",
      " \tfitness: valid cnt: 4498, max: -0.0000, min: -31.7500, mean: -0.5040, std: 1.2650\n",
      "\n",
      "Generation: 87, Cost time: 4.99ms\n",
      " \tfitness: valid cnt: 4490, max: -0.0000, min: -185.0625, mean: -0.5944, std: 3.3433\n",
      "\n",
      "Generation: 88, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4502, max: -0.0000, min: -34.7500, mean: -0.5534, std: 1.5494\n",
      "\n",
      "Generation: 89, Cost time: 6.00ms\n",
      " \tfitness: valid cnt: 4493, max: -0.0000, min: -45.2500, mean: -0.5403, std: 1.4752\n",
      "\n",
      "Generation: 90, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4503, max: -0.0000, min: -65.2500, mean: -0.5972, std: 1.9485\n",
      "\n",
      "Generation: 91, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4495, max: -0.0000, min: -49.2500, mean: -0.5832, std: 1.7851\n",
      "\n",
      "Generation: 92, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4474, max: -0.0000, min: -47.5000, mean: -0.6468, std: 2.2075\n",
      "\n",
      "Generation: 93, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4555, max: -0.0000, min: -125.2500, mean: -0.6386, std: 2.7262\n",
      "\n",
      "Generation: 94, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4538, max: -0.0000, min: -130.2500, mean: -0.6715, std: 3.1120\n",
      "\n",
      "Generation: 95, Cost time: 5.24ms\n",
      " \tfitness: valid cnt: 4552, max: -0.0000, min: -81.2500, mean: -0.6517, std: 2.5728\n",
      "\n",
      "Generation: 96, Cost time: 6.00ms\n",
      " \tfitness: valid cnt: 4492, max: -0.0000, min: -83.2500, mean: -0.6163, std: 2.2987\n",
      "\n",
      "Generation: 97, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4541, max: -0.0000, min: -61.5000, mean: -0.6762, std: 2.4196\n",
      "\n",
      "Generation: 98, Cost time: 5.03ms\n",
      " \tfitness: valid cnt: 4537, max: -0.0000, min: -54.8750, mean: -0.6353, std: 2.0200\n",
      "\n",
      "Generation: 99, Cost time: 5.00ms\n",
      " \tfitness: valid cnt: 4541, max: -0.0000, min: -102.2500, mean: -0.6379, std: 2.2220\n",
      "\n",
      "Generation limit reached!\n"
     ]
    }
   ],
   "source": [
    "# We wrap it in a StandardPipeline for convenience:\n",
    "pipeline = StandardPipeline(\n",
    "    algorithm,\n",
    "    problem,\n",
    "    generation_limit=100,\n",
    ")\n",
    "\n",
    "# Run the pipeline and get the best solution\n",
    "best = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions from best: tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best solution on the XOR inputs:\n",
    "pred_res = best.forward(XOR_INPUTS)\n",
    "print(\"Predictions from best:\", pred_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the best solution:\n",
    "\n",
    "# Check each parts of the solution:\n",
    "best.A.to_sympy_expr()  # use \"A\" because we named it in the formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0*(x0 - 0.5)*(x1 - 0.5)/(x2 - 0.5)\n"
     ]
    }
   ],
   "source": [
    "print(best.B.to_sympy_expr())\n",
    "print(best.C.to_sympy_expr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{1.0 \\left(x_{0} - 0.5\\right) \\left(x_{1} - 0.5\\right)}{x_{2} - 0.5} + 0.5$"
      ],
      "text/plain": [
       "1.0*(x0 - 0.5)*(x1 - 0.5)/(x2 - 0.5) + 0.5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the whole solution:\n",
    "best.to_sympy_expr(lambda A, B, C: A + B * C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
